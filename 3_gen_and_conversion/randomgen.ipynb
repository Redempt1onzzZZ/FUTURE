{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984166f2-0f50-473d-9277-53f2a0a31aa2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm  \n",
    "\n",
    "def read_apis(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        apis = [line.strip() for line in file.readlines()]\n",
    "    return apis\n",
    "\n",
    "def generate_and_save(api_name, save_path, apis):\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    \n",
    "    model_id = \"./2_finetune/combined_model\" #change this to the path of the fine-tuned model\n",
    "    quantization_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_compute_dtype=torch.float16\n",
    "    )\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        quantization_config=quantization_config,\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "\n",
    "    # File to record the names of saved files where tags were not found\n",
    "    log_filename = \"./log.txt\"\n",
    "\n",
    "    for i in tqdm(range(1000), desc=f\"Generating for {api_name}\"):\n",
    "        # Cycle through the API list\n",
    "        api = apis[i % len(apis)]\n",
    "        prompt = f\"<s>[INST] Generate code snippet that calls the '{api}' API. [/INST]\"\n",
    "        \n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=False).to(\"cuda\")\n",
    "        outputs = model.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            max_new_tokens=200,\n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "            temperature=0.1,\n",
    "        )\n",
    "        outputs = outputs[0].to(\"cpu\")\n",
    "        decoded_output = tokenizer.decode(outputs)\n",
    "        \n",
    "        # Try to extract the first [ANS] to [INST] block\n",
    "        ans_start_idx = decoded_output.find(\"[/INST]\") + 7\n",
    "        inst_start_idx = decoded_output.find(\"[INST]\", ans_start_idx)\n",
    "        \n",
    "        if ans_start_idx == -1 or inst_start_idx == -1:\n",
    "            print(\"block not found, saving full output.\")\n",
    "            code_between = decoded_output\n",
    "            file_path = os.path.join(save_path, f\"{i+1}_{api_name}_{api}.py\")\n",
    "            with open(log_filename, \"a\") as log_file:\n",
    "                log_file.write(f\"{file_path}\\n\")\n",
    "        else:\n",
    "            code_between = decoded_output[ans_start_idx:inst_start_idx].strip()\n",
    "            file_path = os.path.join(save_path, f\"{i+1}_{api_name}_{api}.py\")\n",
    "            # Save the output to a Python file\n",
    "            with open(file_path, \"w\") as file:\n",
    "                file.write(code_between)\n",
    "            print(f\"Saved: {file_path}\")\n",
    "\n",
    "# Load API names from files\n",
    "mlx_apis = read_apis(\"./2_finetune/api_info_extraction/api_list/mlx_api.txt\")\n",
    "mindspore_apis = read_apis(\"./2_finetune/api_info_extraction/api_list/mindspore_api.txt\")\n",
    "oneflow_apis = read_apis(\"./2_finetune/api_info_extraction/api_list/oneflow_api.txt\")\n",
    "\n",
    "apis_dict = {\n",
    "    \"MLX\": mlx_apis,\n",
    "    \"MindSpore\": mindspore_apis,\n",
    "    \"OneFlow\": oneflow_apis\n",
    "}\n",
    "\n",
    "base_path = \"./randomgen\" #change this to the path of the folder to save the generated codes\n",
    "\n",
    "# Generate code for each API using the list of APIs from files\n",
    "for api_name, apis in apis_dict.items():\n",
    "    generate_and_save(api_name, os.path.join(base_path, api_name), apis)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
